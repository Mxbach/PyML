{"cells": [{"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["# Exercise Sheet 3: Advanced NumPy\n", "\n", "In the third exercise sheet we will work on advanced NumPy topics and application on machine learning tasks. You will implement a complete data science pipline, starting with data loading, plotting and data exploration, and finally implementing a machine learning model and applying it to the data.\n", "\n", "Please do not use the following functions throughout the notebook:\n", "\n", "- `map`\n", "- `sum` (`np.sum` is allowed)\n", "- `filter`\n", "- `np.vectorize`\n", "- `np.fromiter`\n", "- `np.fromfunction`\n", "- `np.apply_along_axis`"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Testing\n", "Each task is provided with tests.\n", "You can use these tests to practice test driven development (TDD), and to check your work, but please note that using them will likely make the tasks easier.\n", "Please also note that the tests may not be exhaustive, i.e. even when passing all tests, your solution can still be imperfect, so please feel free to add to these tests to help assure the correctness of your solution."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Please execute this setup cell.\n", "from pathlib import Path\n", "from unittest import TestCase\n", "\n", "t = TestCase()\n", "\n", "from minified import max_allowed_loops, no_imports\n", "from illegal import IllegalContext, create_no_loop_illegals"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["## 1. Clustering \n", "### 1.1: Load data\n", "\n", "Read the data from the file data.csv and save it in a dictionary. The letters in data.csv are the assigned labels and their corresponding data points. Each data point is two-dimensional and consists of the given x- and y-values. Return a dictionary with the letters/labels as keys. The value assigned to each key should be a list of x- and y-values. \n", "\n", "* Do not forget to cast the values to float."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@no_imports\n", "@max_allowed_loops(1)\n", "def read_from_file(file: str = \"data.csv\") -> dict:\n", "    \"\"\"\n", "    Opens a csv file and parses it line by line. Each line consists of a label and two\n", "    data dimensions. The function returns a dictionary where each key is a label and\n", "    the value is a list of all the data points that have that label. Each data point\n", "    is represented by a pair (2-element tuple) of floats.\n", "\n", "    Args:\n", "        file: The path to the file to open and parse. Defaults to\n", "              \"data.csv\".\n", "\n", "    Returns:\n", "        dict: The parsed contents of the csv file\n", "    \"\"\"\n", "\n", "### Please enter your solution here ###\n", "\n", "    return D"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def test_read_from_file():\n", "    tiny_result = read_from_file(file=\"tiny.csv\")\n", "    print(\"tiny_result\", tiny_result)\n", "    tiny_expected = {\"A\": [(0.8, 0.9), (0.2, 0.3)], \"B\": [(0.9, 0.1)], \"C\": [(2.0, 4.0)]}\n", "    t.assertEqual(tiny_result, tiny_expected)\n", "\n", "    D = read_from_file(file=\"data.csv\")\n", "    print(f\"Keys of D: {D.keys()}\", end=\"\\n\\n\")\n", "    for k, v in D.items():\n", "        print(f\"{len(v)} data points were assigned the label {k}\")\n", "\n", "    # Test All types\n", "    t.assertIsInstance(D, dict)\n", "    for d in D:\n", "        t.assertIsInstance(d, str)\n", "        t.assertIsInstance(D[d], list)\n", "        for el in D[d]:\n", "            t.assertIsInstance(el, tuple)\n", "            t.assertIsInstance(el[0], float)\n", "            t.assertIsInstance(el[1], float)\n", "            \n", "    letters = \"MNU\"\n", "    t.assertEqual(set(D.keys()), set(letters))\n", "    t.assertTrue(all(len(v) > 99 for v in D.values()))\n", "    read_from_file.assert_not_too_many_loops()\n", "    read_from_file.assert_no_imports()\n", "\n", "test_read_from_file()\n", "\n", "letters = \"MNU\"\n", "D = read_from_file(file=\"data.csv\")"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["### 1.2 Stack data\n", "\n", "Use NumPy to stack all of the $N$ data points from the dictionary into one matrix $X$, containing the data.\n", "\n", "Additionally, create one array $y$ with the corresponding integer labels. \n", "\n", "Each datapoint $x_i \\in X, \\> i = \\overline{1..N}$ is of dimension $D=2$. The label assigned to a datapoint has to be a positive integer. Every letter label should map to one integer label in $y$ accordingly.\n", "\n", "Mapping example: $A \\rightarrow 0,\\> C \\rightarrow 1,\\> K \\rightarrow 2, ...$ (The order of the keys/labels defines the numeric label. The first key is mapped to 0 and so on.)\n", "\n", "* Dataset $X$: $$\\Large X \\in \\mathbb{R}^{(N, D)}$$\n", "* Labels $y$: $$\\Large y \\in \\mathbb{N}^{(N,)} $$"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "\n", "illegals = create_no_loop_illegals(np, __builtins__)\n", "no_loop_illegals_context = IllegalContext(illegals, globals())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@no_imports\n", "@max_allowed_loops(1)\n", "def stack_data(D: dict) -> tuple[np.ndarray, np.ndarray]:\n", "    \"\"\"\n", "    Convert a dictionary dataset into two arrays of data and labels. The dictionary\n", "    keys represent the labels and the value mapped to each key is a list that\n", "    contains all the data points belonging to that label. The output is two arrays\n", "    the first is the data points in a single 2d array and a vector of integers\n", "    with the corresponding label for each datapoint. The order of the data points is\n", "    preserved according to the order in the dictionary and the lists.\n", "\n", "    The labels are converted from a string to a unique int.\n", "\n", "    The data points are entered in the same order as the keys in the `D`. First,\n", "    all the data points of the first key are entered then the second and so on.\n", "    Within one label order also remains.\n", "\n", "    Args:\n", "        D: The dictionary that is supposed to get stacked.\n", "\n", "    Returns:\n", "        tuple: The two output arrays. The first is a float matrix containing all the\n", "               data points. The second is an int-vector containing the labels for each data point.\n", "    \"\"\"\n", "\n", "\n", "### Please enter your solution here ###\n", "\n", "    return X, y"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def test_stack_data():\n", "    tiny_expected_X, tiny_expected_y = (\n", "        np.array(\n", "            [\n", "                [0.0, 0.1],\n", "                [0.9, 0.7],\n", "                [0.8, 0.3],\n", "            ]\n", "        ),\n", "        np.array([0, 1, 1]),\n", "    )\n", "    tiny_result_X, tiny_result_y = stack_data(\n", "        {\"B\": [(0.0, 0.1)], \"A\": [(0.9, 0.7), (0.8, 0.3)]}\n", "    )\n", "    print(tiny_result_X, tiny_result_y)\n", "    np.testing.assert_allclose(tiny_expected_X, tiny_result_X)\n", "    np.testing.assert_allclose(tiny_expected_y, tiny_result_y)\n", "\n", "    X, y = stack_data(D)\n", "    print(X.shape, y.shape)\n", "    print(X.dtype, y.dtype)\n", "\n", "    expected_len = sum(len(x) for x in D.values())\n", "    print(f\"Expected length for X, y: {expected_len}\")\n", "\n", "    t.assertEqual(X.shape, (expected_len, 2))\n", "    t.assertEqual(y.shape, (expected_len,))\n", "\n", "    t.assertEqual(X.dtype, np.float64)\n", "    t.assertEqual(y.dtype, np.int64)\n", "\n", "    t.assertEqual(set(y), set(range(len(D))))\n", "\n", "    with no_loop_illegals_context:\n", "        X, y = stack_data(D)\n", "\n", "    stack_data.assert_not_too_many_loops()\n", "    stack_data.assert_no_imports()\n", "\n", "test_stack_data()\n", "\n", "X, y = stack_data(D)"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["### 1.3 Return clusters\n", "\n", "Write a function that returns a list of all $k$ clusters $C$. A cluster $C_k$ is composed of every datapoint $X_i$ assigned with the label $k$. There are as many clusters $C_k$ as there are unique labels in $y$.\n", "\n", "\n", "$$\\Large{\\mathcal{C} = \\{ C_1, C_2, \\cdots, C_k \\},\\quad k = \\overline{1..K}}$$\n", "\n", "<br>\n", "\n", "$$\\Large C_k \\in \\mathbb{R}^{(N_k, D)}$$"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@no_imports\n", "@max_allowed_loops(1)\n", "def get_clusters(X: np.ndarray, y: np.ndarray) -> list[np.ndarray]:\n", "    \"\"\"\n", "    Receives a labeled dataset and splits the data points according to the label.\n", "\n", "    Args:\n", "        X: The dataset\n", "        y: The label for each point in the dataset\n", "\n", "    Returns:\n", "        list: A list of arrays where the elements of each array are data points belonging to\n", "              the label on that index\n", "\n", "    Example:\n", "    >>> get_clusters(\n", "            np.array([[0.8, 0.7], [0, 0.4], [0.3, 0.1]]),\n", "            np.array([0,1,0])\n", "        )\n", "    >>> [array([[0.8, 0.7],[0.3, 0.1]]),\n", "         array([[0. , 0.4]])]\n", "    \"\"\"\n", "\n", "### Please enter your solution here ###\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def test_get_clusters():\n", "    tiny_result = get_clusters(\n", "        np.array(\n", "            [\n", "                [0.8, 0.7],\n", "                [0, 0.4],\n", "                [0.3, 0.1],\n", "            ]\n", "        ),\n", "        np.array([0, 1, 0]),\n", "    )\n", "    print(tiny_result)\n", "    tiny_expected = [\n", "        np.array(\n", "            [\n", "                [0.8, 0.7],\n", "                [0.3, 0.1],\n", "            ]\n", "        ),\n", "        np.array(\n", "            [\n", "                [0.0, 0.4],\n", "            ]\n", "        ),\n", "    ]\n", "    for r, e in zip(tiny_result, tiny_expected):\n", "        np.testing.assert_allclose(r, e)\n", "\n", "    clusters = get_clusters(X, y)\n", "    # output is a list\n", "    t.assertIsInstance(clusters, list)\n", "    t.assertEqual(len(letters), len(clusters))\n", "\n", "    # all elements are arrays\n", "    for el in clusters:\n", "        t.assertIsInstance(el, np.ndarray)\n", "\n", "    t.assertEqual(sum(map(len, clusters)), len(X))\n", "\n", "    with no_loop_illegals_context:\n", "        clusters = get_clusters(X, y)\n", "\n", "\n", "    get_clusters.assert_not_too_many_loops()\n", "    get_clusters.assert_no_imports()\n", "\n", "test_get_clusters()\n", "\n", "clusters = get_clusters(X, y)"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["### 1.4 Split train test data\n", "\n", "Split the data $X$ into training and test data.\n", "\n", "* Return a list of clusters for training and a list of cluster for testing.\n", "\n", "* Utilize the function `train_test_idxs` from utils to split the data.\n", "\n", "* The train-test ratio should be 80-20\n", "\n", "* Use the function implemented in Exercise 1.3 __get_clusters(X,y)__ to get the clusters.\n", "\n", "* Remember that when you split the dataset you need to keep the relationship between the data and the labels. Do not split the data and labels independently"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from utils import train_test_idxs\n", "\n", "print(\"train_test_idxs specification:\\n\", train_test_idxs.__doc__)\n", "\n", "train_indices, test_indices = train_test_idxs(L=20, test_ratio=0.3)\n", "print(f\"train_indices = {train_indices}\")\n", "print(f\"test_indices = {test_indices}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@no_imports\n", "@max_allowed_loops(0)\n", "def split(X: np.ndarray, y: np.ndarray) -> tuple[list[np.ndarray], list[np.ndarray]]:\n", "    \"\"\"\n", "    Split the data into train and test sets. The training and test set are\n", "    clustered by label using `get_clusters`. The size of the training set\n", "    is 80% of the whole dataset.\n", "\n", "    Args:\n", "        X: The dataset (2d)\n", "        y: The label of each datapoint in the dataset `X` (1d)\n", "\n", "    Returns:\n", "        tuple: The clustered training and test sets\n", "    \"\"\"\n", "\n", "### Please enter your solution here ###\n", "\n", "\n", "    return tr_clusters, te_clusters"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def test_split():\n", "    output = split(X, y)\n", "    tr_clusters, te_clusters = output\n", "    t.assertIsInstance(output, tuple)\n", "    t.assertIsInstance(tr_clusters, list)\n", "    t.assertIsInstance(te_clusters, list)\n", "\n", "\n", "    t.assertEqual(len(tr_clusters), len(te_clusters))\n", "    t.assertEqual(len(tr_clusters), len(letters))\n", "    t.assertEqual(len(te_clusters), len(letters))\n", "\n", "    for el in tr_clusters + te_clusters:\n", "        t.assertIsInstance(el, np.ndarray)\n", "\n", "\n", "    n_in_train = sum(map(len, tr_clusters))\n", "    n_in_test = sum(map(len, te_clusters))\n", "    t.assertEqual(n_in_train + n_in_test, len(X))\n", "\n", "    percent_train = n_in_train / len(X)\n", "    print(f\"percent_train = {percent_train}\")\n", "    t.assertGreaterEqual(percent_train, 0.79)\n", "    t.assertLessEqual(percent_train, 0.81)\n", "\n", "test_split()\n", "\n", "tr_clusters, te_clusters = split(X, y)"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["### 1.5 Cluster mean\n", "\n", "Compute the mean $\\mu_k$ of each cluster $C_k$. Return a list of all cluster means $\\mu$.\n", "\n", "\n", "$$\\Large{\\mu = \\{ \\mu_1, \\mu_2, \\cdots, \\mu_k \\},\\quad k = \\overline{1..K}}$$\n", "\n", "\n", "\n", "* Number of elements in a cluster $k$:\n", "$$\\Large{N_k = | C_k |, \\quad C_k \\in \\mathbb{R}^{(N_k, D)}}$$\n", "\n", "\n", "\n", "* The $k$-th cluster mean $\\mu_k$:\n", "$$\\Large{ \\mu_k = \\frac{1}{N_k}\\sum_{x_i \\in C_k} x_i }$$"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@no_imports\n", "@max_allowed_loops(1)\n", "def calc_means(clusters: list[np.ndarray]) -> np.ndarray:\n", "    \"\"\"\n", "    For a collection of clusters calculate the mean for each cluster\n", "\n", "    Args:\n", "        clusters: A list of 2d arrays. Each array in the list corresponds to a cluster\n", "\n", "    Returns:\n", "        np.ndarray: A matrix where each row represents the mean of a cluster\n", "    \"\"\"\n", "\n", "### Please enter your solution here ###\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def test_calc_mean():\n", "    tiny_clusters = [\n", "        np.array([[0.2, 0.3], [0.1, 0.2]]),\n", "        np.array([[0.8, 0.9], [0.7, 0.5], [0.6, 0.7]]),\n", "    ]\n", "    tiny_result = calc_means(tiny_clusters)\n", "    print(tiny_result, end=\"\\n\\n\")\n", "    tiny_expected = np.array([[0.15, 0.25], [0.7, 0.7]])\n", "    np.testing.assert_allclose(tiny_result, tiny_expected)\n", "\n", "    means = calc_means(tr_clusters)\n", "    print(means)\n", "    t.assertIsInstance(means, np.ndarray)\n", "    t.assertEqual(means.shape, (len(letters), 2))\n", "\n", "test_calc_mean()\n", "\n", "means = calc_means(tr_clusters)"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["## 2. Visualization\n", "### 2.1 Scatter plot of clusters\n", "\n", "- Create a scatter plot of size 8x8. \n", "\n", "- Plot each datapoint of a cluster $x_{ik} \\in  C_k$ as dots with an alpha value of 0.6 and a label. \n", "\n", "- The plot label should contain both the cluster's letter label and its integer label. \n", "\n", "- Further, plot the cluster's mean $\\mu_k$ as a red cross of size 7. The plot should also have a label for each cluster's mean, giving information on its exact coordinates. \n", "\n", "- The title of the plot should be _'Scatter plot of the clusters'_ in font size 20.\n", "\n", "* Label for the scatter plots example: _A = 0_\n", "* Label for the cluster means example (use LaTeX): _$\\mu_A:$[1.23  0.56]_\n", "\n", "- If the mean of each cluster is not provided, use `calc_means(clusters)` to calculate the means."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "\n", "%matplotlib inline"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@no_imports\n", "def plot_scatter_and_mean(clusters: list[np.ndarray], letters: str, means=None) -> None:\n", "    \"\"\"\n", "    Create a scatter plot visualizing each cluster and its mean\n", "\n", "    Args:\n", "        clusters: A list containing arrays representing each cluster\n", "        letters: The \"name\" of each cluster\n", "        means: The mean of each cluster. If `None` the mean of each cluster in `clusters` should be calculated and used.\n", "    \"\"\"\n", "    assert len(letters) == len(clusters)\n", "\n", "\n", "### Please enter your solution here ###\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_scatter_and_mean(tr_clusters, letters, means=None)"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["### 2.2 Plot clusters projected to onto an axis \n", "\n", " - To make it easier to visually analyse the the differences between clusters, the data can be projected onto an axis. Plot a histogram for the projection onto the given axis. \n", " \n", " - The histogram should have 30 bins, be 50% transparent and labeled. The area under the histogram should be normalized and sum to 1 to represent a proper distribution. It can be done by setting the corresponding parameter.  - The bars width should have 4/5 of the bins width.\n", "\n", "\n", "- Create a histogram of size 14x5.\n", "* Plot the mean of each cluster as a vertical, dashed, red line.\n", "* Label for the histograms example: _A_\n", "* The title of the plot should be dynamic, have a font size of 20 and explain the axis of the projection, e.g. \"Projection to axis 0 histogram plot\" or \"Projection to axis 1 histogram plot\", depending on the axis."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@no_imports\n", "def plot_projection(clusters: list[np.ndarray], letters: str, means: np.ndarray, axis: int=0):\n", "    \"\"\"\n", "    Plot a histogram of the dimension provided in `axis`.\n", "\n", "    Args:\n", "        clusters: The clusters from which to create the histogram\n", "        letters: The string representation of each class\n", "        means: The mean of each class\n", "        axis: The axis from which to create the histogram. Defaults to 0.\n", "    \"\"\"\n", "\n", "### Please enter your solution here ###\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_projection(tr_clusters, letters, means, axis=0)"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["## 3. Analyse cluster distributions\n", "### 3.1 Within cluster covariance\n", "\n", "Compute the within-cluster covariance $S_w$ to further analyze the distribution of the data in the clusters. Sum up the covariance matrices of each cluster to get the one average within-cluster covariance matrix. **This is shown in the formula below.** Covariance matrices describe the relationship between the x and y dimensions of the data.\n", "\n", "$$\\boxed{\\Large{S_w  = \\sum_{k=1}^K \\sum_{x_i \\in C_k} (x_i - \\mu_k)} (x_i - \\mu_k)^{\\top}, \\quad S_w \\in \\mathbb{R}^{(D, D)}}$$\n", "\n", "\n", "* Reminder: Data $C$ is a set of clusters $C_k$, where $K$ is the total number of clusters. $${\\mathcal{C} = \\{ C_1, C_2, \\cdots, C_k \\},\\quad k = \\overline{1..K}}$$\n", "\n", "* Number of elements in a cluster $k$: $${N_k = | C_k |, \\quad C_k \\in \\mathbb{R}^{(N_k, D)}}$$\n", "<br>\n", "\n", "* $k$-th cluster mean $\\mu_k$: $${ \\mu_k = \\frac{1}{N_k}\\sum_{x_i \\in C_k} x_i }$$"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@no_imports\n", "@max_allowed_loops(1)\n", "def within_cluster_cov(clusters: list[np.ndarray]) -> np.ndarray:\n", "    \"\"\"\n", "    Calculate the within-class covariance for a collection of clusters\n", "\n", "    Args:\n", "        clusters: A list of clusters each consisting of\n", "        an array of data points.\n", "\n", "    Returns:\n", "        np.ndarray: The within-cluster covariance\n", "\n", "    Example:\n", "        >>> within_cluster_cov(\n", "            [array([[0.2, 0.3], [0.1, 0.2]]), array([[0.8, 0.9], [0.7, 0.5], [0.6, 0.7]])]\n", "        )\n", "        >>> array([[0.025, 0.025],\n", "                   [0.025, 0.085]])\n", "    \"\"\"\n", "    d = clusters[0].shape[1]\n", "    S_w = np.zeros((d, d))\n", "\n", "### Please enter your solution here ###\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def test_within_cluster_cov():\n", "    tiny_clusters = [\n", "        np.array([[0.2, 0.3], [0.1, 0.2]]),\n", "        np.array([[0.8, 0.9], [0.7, 0.5], [0.6, 0.7]]),\n", "    ]\n", "    tiny_expected = np.array([[0.025, 0.025], [0.025, 0.085]])\n", "    tiny_result = within_cluster_cov(tiny_clusters)\n", "    print(tiny_result)\n", "    np.testing.assert_allclose(tiny_expected, tiny_result)\n", "\n", "    S_w = within_cluster_cov(tr_clusters)\n", "    print(S_w)\n", "    t.assertIsInstance(S_w, np.ndarray)\n", "    t.assertEqual(S_w.shape, (2, 2))\n", "\n", "    # check if symmetric\n", "    np.testing.assert_allclose(S_w, S_w.T)\n", "\n", "test_within_cluster_cov()\n", "\n", "S_w = within_cluster_cov(tr_clusters)"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["### 3.2 Between cluster covariance\n", "\n", "To compute the between cluster covariance, the calculation of the mean of means is necessary. In the function `calc_mean_of_means(clusters)` you must reuse your function `calc_means(clusters)`.\n", "\n", "\n", "* Mean of means: $$\\Large{ \\mu = \\frac{1}{N}\\sum_{C_i \\in \\mathcal{C}}{C_i}},\\quad \\text{where}\\quad N = |\\mathcal{C}|$$\n", "\n", "\n", "The between-cluster covariance describes the relation of the data points from one cluster to the other. It focuses on the differences rather than the similarities. **You only have to implement the given formulas**, and do not need to fully understand the underlying concept. \n", "\n", "* Between cluster covariance: $$\\boxed{\\Large{S_b = \\sum_{k=1}^K  N_k (\\mu_k - \\mu) (\\mu_k - \\mu)^{\\top}}}$$\n", "\n", "where $\\mu$ represents the mean of means and $\\mu_k$ represents the mean of the $k$-th cluster.\n", "\n", "*Hint:* For the `between_cluster_cov` consider the `np.outer` function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@no_imports\n", "@max_allowed_loops(0)\n", "def calc_mean_of_means(clusters: list[np.ndarray]) -> np.ndarray:\n", "    \"\"\"\n", "    Given a collection of data points divided into clusters, calculate the\n", "    mean of all cluster means.\n", "    \n", "    Args:\n", "        clusters: A list of clusters represented in arrays\n", "\n", "    Returns:\n", "        np.ndarray: A single data point that represents the mean of all the\n", "                    cluster means\n", "    \"\"\"\n", "\n", "### Please enter your solution here ###\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def test_calc_mean_of_means():\n", "    tiny_result = calc_mean_of_means(\n", "        [\n", "            np.array([[0.222, 0.333], [0.1, 0.2]]),\n", "            np.array([[0.8, 0.9], [0.7, 0.5], [0.6, 0.7]]),\n", "        ]\n", "    )\n", "    print(tiny_result)\n", "    tiny_expected = np.array([0.4305, 0.48325])\n", "    np.testing.assert_allclose(tiny_expected, tiny_result)\n", "\n", "    mean_of_means = calc_mean_of_means(tr_clusters)\n", "    print(mean_of_means)\n", "    t.assertIsInstance(mean_of_means, np.ndarray)\n", "    t.assertEqual(mean_of_means.shape, (2,))\n", "\n", "test_calc_mean_of_means()\n", "mean_of_means = calc_mean_of_means(tr_clusters)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@no_imports\n", "@max_allowed_loops(1)\n", "def between_cluster_cov(clusters: list[np.ndarray],\n", "                        cluster_means: list[np.ndarray],\n", "                        mean_of_means: np.ndarray) -> np.ndarray:\n", "    \"\"\"\n", "    Calculate the covariance between clusters.\n", "\n", "    Args:\n", "        clusters: A list of data points divided by cluster\n", "        cluster_means: A list of vectors representing the mean of each cluster\n", "        mean_of_means: A vector, the mean of all data points\n", "\n", "    Returns:\n", "        np.ndarray: Covariance between clusters\n", "    \"\"\"\n", "    d = clusters[0].shape[1]\n", "    S_b = np.zeros((d, d))\n", "\n", "    # BEGIN SOLUTION\n", "    mus = cluster_means  # I\n", "    for mu, cluster in zip(mus, clusters):  # II\n", "        N_c = cluster.shape[0]  # I\n", "        outer = np.outer((mu - mean_of_means), (mu - mean_of_means))  # III\n", "        S_b += N_c * outer  # x @ x.T # II\n", "\n", "    return S_b\n", "\n", "### Please enter your solution here ###\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def test_between_cluster_cov():\n", "    tiny_clusters = [\n", "        np.array([[0.2, 0.3], [0.1, 0.2]]),\n", "        np.array([[0.8, 0.9], [0.7, 0.5], [0.6, 0.7]]),\n", "    ]\n", "    tiny_means = [np.array([0.15, 0.25]), np.array([0.7, 0.7])]\n", "    tiny_mean_of_means = np.array([0.425, 0.475])\n", "    between_cluster_cov(tiny_clusters, tiny_means, tiny_mean_of_means)\n", "\n", "    S_b = between_cluster_cov(tr_clusters, means, mean_of_means)\n", "    print(S_b)\n", "    t.assertIsInstance(S_b, np.ndarray)\n", "    t.assertEqual(S_b.shape, (2, 2))\n", "    np.testing.assert_allclose(S_b, S_b.T)\n", "\n", "    t.assertTrue(np.all(S_b > 3000))\n", "    t.assertTrue(np.all(S_b < 5000))\n", "\n", "test_between_cluster_cov()\n", "\n", "S_b = between_cluster_cov(tr_clusters, means, mean_of_means)"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["### 3.3 Rotation matrix\n", "\n", "Compute rotation matrix $W$. To find the rotation matrix you first need to find a matrix $A$ so that the within-cluster covariance matrix can be transformed into the between-cluster covariance matrix. \n", "\n", "$$\\Large{ S_w A = S_b}$$\n", "\n", "Next, find the eigenvalues of this matrix $A$. The eigenvectors describe the direction in which the matrix $A$ does _not_ transform and instead only scales. These vectors form the rotation matrix, as they show the directions in which the difference between $S_w$ and $S_b$ is maximized. **Implement the given formulas!**\n", "\n", "$$ \\Large{AW = \\lambda W}$$\n", "* Return the rotation matrix and the index of its largest axis (according to the eigenvalues)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@no_imports\n", "@max_allowed_loops(0)\n", "def rotation_matrix(S_w: np.ndarray, S_b: np.ndarray) -> tuple[np.ndarray, int]:\n", "    \"\"\"\n", "    Calculate the transformation matrix given the within- and between cluster\n", "    covariance matrices.\n", "\n", "    Args:\n", "        S_w: The within-cluster covariance\n", "        S_b: The between-cluster covariance\n", "\n", "    Returns:\n", "        tuple: The transformation matrix and the axis along with the transformed data achieves\n", "               maximal variance\n", "    \"\"\"\n", "\n", "### Please enter your solution here ###\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def test_rotation_matrix():\n", "    tiny_S_w = np.array([[0.025, 0.025], [0.025, 0.085]])\n", "    tiny_S_b = np.array([[0.378125, 0.309375], [0.309375, 0.253125]])\n", "    tiny_result_M, tiny_result_max_axis = rotation_matrix(tiny_S_w, tiny_S_b)\n", "    print(tiny_result_M, tiny_result_max_axis)\n", "    tiny_expected_M, tiny_expected_max_axis = (\n", "        np.array([[0.99752952, -0.63323779], [-0.07024856, 0.7739573]]),\n", "        0,\n", "    )\n", "    np.testing.assert_allclose(tiny_expected_M, tiny_result_M)\n", "    np.testing.assert_allclose(tiny_expected_max_axis, tiny_result_max_axis)\n", "\n", "    output = rotation_matrix(S_w, S_b)\n", "    t.assertIsInstance(output, tuple)\n", "    t.assertEqual(len(output), 2)\n", "    W_rot, max_axis = output\n", "    t.assertIsInstance(W_rot, np.ndarray)\n", "    t.assertIsInstance(max_axis, np.int64)\n", "    t.assertEqual(W_rot.shape, (2, 2))\n", "\n", "test_rotation_matrix()\n", "\n", "W_rot, max_axis = rotation_matrix(S_w, S_b)"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["### 3.4 Apply rotation matrix\n", "\n", "Apply the rotation matrix to the clusters and return the rotated clusters in a list. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@no_imports\n", "@max_allowed_loops(1)\n", "def rotate_clusters(W_rot: np.ndarray, clusters: list[np.ndarray]) -> list[np.ndarray]:\n", "    \"\"\"\n", "    Rotate all the data points in all the clusters\n", "\n", "    Args:\n", "        W_rot: The rotation matrix\n", "        clusters: The list of data points divided into clusters that will be rotated\n", "\n", "    Returns:\n", "        list: The rotated data points divided by cluster\n", "    \"\"\"\n", "\n", "### Please enter your solution here ###\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def test_rotate_clusters():\n", "    rad = np.deg2rad(30)\n", "    c, s = np.cos(rad), np.sin(rad)\n", "    rot30 = np.array([[c, -s], [s, c]])\n", "    tiny_clusters = [\n", "        np.array([[0.2, 0.3], [0.1, 0.2]]),\n", "        np.array([[0.8, 0.9], [0.7, 0.5], [0.6, 0.7]]),\n", "    ]\n", "    tiny_rotated_result = rotate_clusters(rot30, tiny_clusters)\n", "    print(tiny_rotated_result)\n", "    tiny_rotated_expected = [\n", "        np.array([[0.32320508, 0.15980762], [0.18660254, 0.12320508]]),\n", "        np.array([[1.14282032, 0.37942286], [0.85621778, 0.0830127], [0.86961524, 0.30621778]]),\n", "    ]\n", "    for r, e in zip(tiny_rotated_result, tiny_rotated_expected):\n", "        np.testing.assert_allclose(r, e)\n", "\n", "    rot_tr_clusters = rotate_clusters(W_rot, tr_clusters)\n", "    t.assertIsInstance(rot_tr_clusters, list)\n", "    for norm, rotated in zip(tr_clusters, rot_tr_clusters):\n", "        t.assertIsInstance(rotated, np.ndarray)\n", "        t.assertEqual(norm.shape, rotated.shape)\n", "\n", "test_rotate_clusters()\n", "\n", "rot_tr_clusters = rotate_clusters(W_rot, tr_clusters)"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["### Goal\n", "\n", "Using the rotated clusters, we can now plot the clusters projected onto the axis with highest eigenvalue as histograms. Here we can draw a more accurate line separating the clusters than we could before. This line can be used for classifying data through drawing a simple line between clusters."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_scatter_and_mean(rot_tr_clusters, letters)\n", "means = calc_means(rot_tr_clusters)\n", "plot_projection(rot_tr_clusters, letters, means, axis=max_axis)"]}], "metadata": {"celltoolbar": "Create Assignment", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.12"}, "vscode": {"interpreter": {"hash": "3b7837e62b9049ed1053017544f4fae907316b15adb741ae0ade272138f0f57a"}}}, "nbformat": 4, "nbformat_minor": 4}